{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Brain Diagnostics\n",
        "This notebook demonstrates the capabilities of the MacePotential (The Brain), including initialization, training (Head-Only), and uncertainty quantification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from ase import Atoms\n",
        "from ase.build import bulk\n",
        "import matplotlib.pyplot as plt\n",
        "from mace.modules import ScaleShiftMACE\n",
        "from mace.modules.blocks import RealAgnosticInteractionBlock\n",
        "from e3nn import o3\n",
        "\n",
        "# Add src to path to import MacePotential\n",
        "# Assuming this notebook is in tutorials_and_uat/cycle_02/\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
        "\n",
        "from src.potentials.mace_impl import MacePotential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_dummy_model(path):\n",
        "    # Minimal parameters for a valid MACE model\n",
        "    model_config = dict(\n",
        "        r_max=4.0,\n",
        "        num_bessel=3,\n",
        "        num_polynomial_cutoff=3,\n",
        "        max_ell=1,\n",
        "        interaction_cls=RealAgnosticInteractionBlock,\n",
        "        interaction_cls_first=RealAgnosticInteractionBlock,\n",
        "        num_interactions=1,\n",
        "        num_elements=2,\n",
        "        hidden_irreps=o3.Irreps('8x0e'),\n",
        "        MLP_irreps=o3.Irreps('8x0e'),\n",
        "        atomic_energies=np.array([0.0, 0.0]),\n",
        "        avg_num_neighbors=1.0,\n",
        "        atomic_numbers=[1, 29], # H, Cu\n",
        "        correlation=1,\n",
        "        gate=torch.nn.functional.silu,\n",
        "    )\n",
        "    \n",
        "    # Create the model wrapper\n",
        "    model = ScaleShiftMACE(\n",
        "        atomic_inter_scale=1.0,\n",
        "        atomic_inter_shift=0.0,\n",
        "        **model_config\n",
        "    )\n",
        "    \n",
        "    # Save it\n",
        "    torch.save(model, path)\n",
        "    print(f\"Saved dummy model to {path}\")\n",
        "\n",
        "# Create the model file\n",
        "create_dummy_model('temp_foundation.model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize the potential with the dummy model\n",
        "pot = MacePotential('temp_foundation.model')\n",
        "print(\"MacePotential initialized successfully.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate synthetic training data (perturbed Copper crystals)\n",
        "training_data = []\n",
        "np.random.seed(42)\n",
        "for i in range(5):\n",
        "    atoms = bulk('Cu', cubic=True)\n",
        "    atoms.rattle(stdev=0.1, seed=i)\n",
        "    training_data.append(atoms)\n",
        "print(f\"Generated {len(training_data)} training structures.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Capture weights to verify freezing logic\n",
        "# Accessing internal model structure - this depends on MACE architecture\n",
        "backbone_weight_before = pot.model.interactions[0].linear.weight.detach().clone()\n",
        "readout_weight_before = pot.model.readouts[-1].linear.weight.detach().clone()\n",
        "\n",
        "print(\"Captured initial weights.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train the model (Head-Only)\n",
        "print(\"Starting training...\")\n",
        "# We don't provide atomic_energies or labels here, MacePotential.train calculates loss against the atoms' own potential energy \n",
        "# But wait, the atoms generated above don't have energies attached!\n",
        "# We need to attach dummy energies/forces to the training data for the loss function to work.\n",
        "# MacePotential.train uses: ref_energies.append(a.get_potential_energy())\n",
        "\n",
        "# Let's attach dummy target values\n",
        "for atoms in training_data:\n",
        "    # Dummy energy: -3.5 eV per atom roughly for Cu\n",
        "    e = -3.5 * len(atoms) + np.random.normal(0, 0.1)\n",
        "    f = np.random.uniform(-0.1, 0.1, size=(len(atoms), 3))\n",
        "    \n",
        "    # Use SinglePointCalculator to attach results\n",
        "    from ase.calculators.singlepoint import SinglePointCalculator\n",
        "    atoms.calc = SinglePointCalculator(atoms, energy=e, forces=f)\n",
        "\n",
        "pot.train(training_data, energy_weight=1.0, forces_weight=1.0)\n",
        "print(\"Training complete.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify that backbone is frozen and readout is updated\n",
        "backbone_weight_after = pot.model.interactions[0].linear.weight\n",
        "readout_weight_after = pot.model.readouts[-1].linear.weight\n",
        "\n",
        "# Backbone should be identical\n",
        "if torch.allclose(backbone_weight_before, backbone_weight_after):\n",
        "    print(\"SUCCESS: Backbone weights are frozen.\")\n",
        "else:\n",
        "    print(\"FAILURE: Backbone weights changed!\")\n",
        "\n",
        "# Readout should change\n",
        "if not torch.allclose(readout_weight_before, readout_weight_after):\n",
        "    print(\"SUCCESS: Readout weights updated.\")\n",
        "else:\n",
        "    print(\"WARNING: Readout weights did not change.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot Uncertainty vs Distortion\n",
        "distortion_levels = np.linspace(0, 0.5, 10)\n",
        "avg_uncertainties = []\n",
        "\n",
        "for d in distortion_levels:\n",
        "    atoms = bulk('Cu', cubic=True)\n",
        "    atoms.rattle(stdev=d, seed=42)\n",
        "    # get_uncertainty returns array of scores per atom\n",
        "    u = pot.get_uncertainty(atoms)\n",
        "    avg_uncertainties.append(np.max(u))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(distortion_levels, avg_uncertainties, marker='o-')\n",
        "plt.xlabel(\"Distortion Level (stdev)\")\n",
        "plt.ylabel(\"Max Normalized Uncertainty\")\n",
        "plt.title(\"Uncertainty vs. Distortion\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify u_max normalization\n",
        "print(f\"Model u_max: {pot.u_max}\")\n",
        "\n",
        "# Check that training data scores are <= 1.0 (approx)\n",
        "max_train_score = 0.0\n",
        "for atoms in training_data:\n",
        "    u = pot.get_uncertainty(atoms)\n",
        "    max_train_score = max(max_train_score, np.max(u))\n",
        "\n",
        "print(f\"Max score on training set: {max_train_score}\")\n",
        "\n",
        "if max_train_score <= 1.001:\n",
        "    print(\"SUCCESS: Training data uncertainty is properly normalized (<= 1.0).\")\n",
        "else:\n",
        "    print(f\"FAILURE: Training data uncertainty {max_train_score} > 1.0\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}